# Redis



如何评估redis的性能：

1. 延时（任何阻塞性的操作都会导致长尾延迟的产生）
2. 网络阻塞

   



## 开篇——如何学习Redis

### 为什么使用Redis？

关键在于性能与可靠性。

> 其实，一个可行的解决方案就是使用非易失内存NVM，因为它既能保证高速的读写，又能快速持久化数据。



### redis的应用

- 缓存
- 数据库
- 分布式锁



### 常见的坑

- CPU 使用上的“坑”，例如数据结构的复杂度、跨 CPU 核的访问；
- 内存使用上的“坑”，例如主从同步和 AOF 的内存竞争；
- 存储持久化上的“坑”，例如在 SSD 上做快照的性能抖动；
- 网络通信上的“坑”，例如多实例时的异常网络丢包。



### 学习系统全景图

两大维度分别是**系统维度**和**应用维度**，三大主线分别是**高性能、高可靠、高可拓展**。更深一步，两大维度和三大主线的系统方法论可以**迁移到大部分的中间件体系学习**中。

对于系统维度，需要了解Redis的各项关键技术的设计原理，为之后判断和推理打下基础。是一个”建基“的过程。其次，在这些设计中，你还能学到一些优雅的系统设计规范。

在应用维度上，我建议你按照两种方式学习: “**应用场景驱动**”和“**典型案例驱动**”，一个是“面”的梳理，一个是“点”的掌握。

![Redis路径](https://i.loli.net/2021/03/24/p7bOVhx8oNKkAzP.jpg)



### Redis各大典型的问题

![典型问题](https://i.loli.net/2021/03/24/5Vf69YKBvsPhMpH.jpg)



---

- [JAVA秘籍之Redis BigKey - 知乎](https://zhuanlan.zhihu.com/p/259719544)



## 基本架构

一般而言，内存键值数据库（例如 Redis）采用哈希表作为索引，很大一部分原因在于，其键值数据基本都是保存在内存中的，而内存的高性能随机访问特性可以很好地与哈希表 O(1) 的操作复杂度相匹配。

但是，键值数据库的键值对通常大小不一，glibc 的分配器在处理随机的大小内存块分配时，表现并不好。一旦保存的键值对数据规模过大，就可能会造成较严重的内存碎片问题

对比memcache：

例如，Memcached 支持的 value 类型仅为 String 类型，而 Redis 支持的 value 类型包括了 String、哈希表、列表、集合等。

**Redis 能够在实际业务场景中得到广泛的应用，就是得益于支持多样化类型的 value。**



## 数据结构

说到这儿，你肯定会说：“这个我知道，不就是 String（字符串）、List（列表）、Hash（哈希）、Set（集合）和 Sorted Set（有序集合）吗？”其实，这些只是 Redis 键值对中值的数据类型，也就是数据的保存形式。而这里，我们说的数据结构，是要去看看它们的底层实现。简单来说，底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。它们和数据类型的对应关系如下图所示：

![Redis数据结构与底层数据结构](https://i.loli.net/2021/03/24/rEg6WKaoZn8Olt7.jpg)



### 键和值的组织

![全局哈希表](https://i.loli.net/2021/03/24/AO49aZUmbuTiDqe.jpg)

但是，如果你只是了解了哈希表的 O(1) 复杂度和快速查找特性，那么，当你往 Redis 中写入大量数据后，就可能发现操作有时候会突然变慢了。**这其实是因为你忽略了一个潜在的风险点，那就是哈希表的冲突问题和 rehash 可能带来的操作阻塞。**



### 压缩列表（提高内存利用率，节省内存，避免内存碎片）

压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，**压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束**。

![压缩列表数据结构](https://i.loli.net/2021/04/05/D1YqpsFVe8UMAKm.jpg)

在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。



### 跳表

有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，**增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位**，如下图所示：

![跳表](https://i.loli.net/2021/04/05/Bja9RbIglK4htAS.jpg)



### 操作的复杂度：

![复杂度](https://i.loli.net/2021/03/24/GDXZz7IHpQlyTVi.jpg)

单元素操作是基础；

范围操作非常耗时；

统计操作通常高效；

例外情况只有几个。

![image-20210324213723214](https://i.loli.net/2021/03/24/JNcKkoL6yDCbdQR.png)



## 单线程模型（Redis单线程为什么这么快）

我们通常说，Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。

### 多线程开销

通常情况下，在我们采用多线程后，如果没有良好的系统设计，实际得到的结果，其实是右图所展示的那样

![img](https://i.loli.net/2021/03/24/CyBUP5eQqfbLgMa.jpg)

为什么会出现这种情况呢？一个关键的瓶颈在于，系统中通常会存在被多线程同时访问的共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销。

![img](https://i.loli.net/2021/03/24/1tjfqT46onPgFiZ.jpg)

并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，比如说，只是简单地采用一个粗粒度互斥锁，就会出现不理想的结果：即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增加。而且，**采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性**。为了避免这些问题，Redis 直接采用了单线程模式。

epoll多路复用模型

![多路复用模型](https://i.loli.net/2021/04/06/3nV7gItE8XfNHdp.jpg)

为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。





### 为什么单线程快

- **避免多线程的复杂并发控制**
- **使用多路复用IO**
- 优秀的数据结构（跳表和哈希表）
- 在内存上操作

### 瓶颈

- Big Key操作（IO）
- 大数据量的操作或者查询（fork或者查询）



> 2020 年 5 月，Redis 6.0 的稳定版发布了，Redis 6.0 中提出了多线程模型。那么，这个多线程模型和这节课所说的 IO 模型有什么关联？会引入复杂的并发控制问题吗？会给 Redis 6.0 带来多大提升？

- 利用服务器的多核资源
- 分摊网络IO的读写负荷



## 持久化机制

### AOF日志

写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志，如下图所示：

![AOF日志](https://i.loli.net/2021/03/24/x4BMFH5PYEm976c.jpg)

传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。



**写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。**



除此之外，AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作(但是可能会阻塞下一次操作的写操作)。

一个AOF文件例子：

![AOF](https://i.loli.net/2021/03/26/Vr3ULyYk4HlFQKZ.jpg)

为什么先执行命令再记录日志？

- 为了避免额外的检查开销，（只有命令能执行成功，才会被记录到日志中）
- 不会阻塞当前的写操作。



性能和可靠性都是和**写磁盘的时机**相关的。



**三种写回策略**

![img](https://i.loli.net/2021/03/24/16YSp3scKhXaw2j.jpg)



想要获得高性能，就选择 No 策略；如果想要得到高可靠性保证，就选择 Always 策略；如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略。



**AOF文件过大问题**

- 文件系统本身对文件大小有限制，无法保存过大的文件
- 如果文件太大，之后再往里面追加命令记录的话，效率也会变低
- 如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢



**AOF重写机制**（让AOF文件变得更小，可避免一些重复的操作）

![AOF重写](https://i.loli.net/2021/03/26/pwgoOAtnrVPTUij.jpg)



和 AOF 日志由主线程写回不同，重写过程是由后台子进程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。

![img](https://i.loli.net/2021/03/26/OgoGrxflWAmQYnt.jpg)



### RDB快照

给所有数据做快照，也就是全量快照。

- 避免阻塞，使用子进程bgsave进行处理快照。

- 做快照时主线程可以继续修改数据，原因是用用了操作系统的写时复制技术。

![](https://i.loli.net/2021/03/26/OgoGrxflWAmQYnt.jpg)



bgsave虽然不阻塞主进程，但频繁的执行全量快照，会带来两方面的开销：

- 磁盘压力大，造成恶性循环
- fork创建过程会阻塞主线程



**解决办法：增量快照**

![img](https://i.loli.net/2021/03/26/kEMxAO37TGuRV1w.jpg)





Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。

 这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。



![img](https://i.loli.net/2021/03/26/aM7TRdUKqOhvt6u.jpg)



最后，关于 AOF 和 RDB 的选择问题，我想再给你提三点建议：

- 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；
- 如果允许分钟级别的数据丢失，可以只使用 RDB；
- 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。



## 数据同步——主从复制

如果这个实例宕机了，它在恢复期间，是无法服务新来的数据存取请求的。

那我们总说的 Redis 具有高可靠性，又是什么意思呢？其实，这里有两层含义：一是数据尽量少丢失，二是服务尽量少中断。AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是增加副本冗余量，将一份数据同时保存在多个实例上。即使有一个实例出现了故障，需要过一段时间才能恢复，其他实例也可以对外提供服务，不会影响业务使用。



### 主从读写分离模式

- 读操作：主库、从库都可以接收；

- 写操作：首先到主库执行，然后，主库将写操作同步给从库。

![img](https://i.loli.net/2021/03/26/YSech2ir1LKuyUx.jpg)



### 如何进行第一次同步

例如，现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5），我们在实例 2 上执行以下这个命令后，实例 2 就变成了实例 1 的从库，并从实例 1 上复制数据：

```
replicaof  172.16.19.3  6379
```

三个阶段

![img](https://i.loli.net/2021/03/26/vlS1B3ZPj4Y5rsd.jpg)





## 哨兵机制（主机挂了还能不间断的进行服务）

所以，如果主库挂了，我们就需要运行一个新主库，比如说把一个从库切换为主库，把它当成主库。这就涉及到三个问题：

主库真的挂了吗？该选择哪个从库作为主库？怎么把新主库的相关信息通知给从库和客户端呢？



### 哨兵基本流程

![哨兵流程](https://i.loli.net/2021/03/25/jGq1LbudXo8C2Ev.jpg)



我们先看监控。监控是指哨兵进程在运行时，周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的 PING 命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。

这个流程首先是执行哨兵的第二个任务，选主。主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。

然后，哨兵会执行最后一个任务：通知。在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。



### 哨兵挂了？主从库切换

布置哨兵集群，减小误判的概率

如果你部署过哨兵集群的话就会知道，在配置哨兵的信息时，我们只需要用到下面的这个配置项，设置主库的 IP 和端口，并没有配置其他哨兵的连接信息。

```
sentinel monitor <master-name> <ip> <redis-port> <quorum> 
```

**基于Pub/Sub机制的哨兵集群**

**发布/订阅机制**——**只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。**

在主从集群中，主库上有一个名为`“__sentinel__:hello”`的频道，不同哨兵就是通过它来相互发现，实现互相通信的。

例如下面的例子：

![img](https://i.loli.net/2021/03/26/eRN4d6tVGvCKAaz.jpg)

哨兵除了彼此之间建立起连接形成集群外，还需要和从库建立连接。这是因为，在哨兵的监控任务中，它需要对主从库都进行心跳判断，而且在主从库切换完成后，它还需要通知从库，让它们和新主库进行同步。

**哨兵是如何知道从库的 IP 地址和端口的呢？**

这是由哨兵向主库发送 INFO 命令来完成的。就像下图所示，哨兵 2 给主库发送 INFO 命令，主库接受到这个命令后，就会把从库列表返回给哨兵。

![img](https://i.loli.net/2021/03/26/uYdiaGejF5g49NR.jpg)



**哨兵和客户端连接**

但是，哨兵不能只和主、从库连接。因为，主从库切换后，客户端也需要知道新主库的连接信息，才能向新主库发送请求操作。所以，哨兵还需要完成把新主库的信息告诉客户端这个任务。

而且，在实际使用哨兵时，我们有时会遇到这样的问题：如何在客户端通过监控了解哨兵进行主从切换的过程呢？比如说，主从切换进行到哪一步了？这其实就是要求，客户端能够获取到哨兵集群在监控、选主、切换这个过程中发生的各种事件。此时，我们仍然可以依赖 pub/sub 机制，来帮助我们完成哨兵和客户端间的信息同步。

从本质上说，哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub/sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。

![img](https://i.loli.net/2021/04/07/IbaEolYSpKjFGVc.jpg)



最终，**哨兵与哨兵之间**(订阅发布机制)、**哨兵与从库之间**（INFO命令）、哨兵与客户端之间，都能够相互通信。



### 由哪个哨兵进行主从切换

投票仲裁



**哨兵集群超>=quorum，判断客观下线**，

**票数 >= N/2+1成为Leader**



是不是哨兵越多越好？

并不是，当哨兵越来越多的时候，选举Leader以及网络通信的时间就会越来越长，造成用户体验的不好。



## 数据分片（切片集群）—— Redis Cluster 方案

![img](https://i.loli.net/2021/03/26/mjfcFqon9Vt2H58.jpg)

使用增加实例的方式来增加集群的内存空间



主要考虑到大的数据量进行RDB持久化进行fork会造成较大的时延。所以横向拓展进行切片是一种比较好的处理方式。





纵向拓展：

1. 当使用 RDB 对数据进行持久化时，如果数据量增加，需要的内存也会增加，主线程 fork 子进程时就可能会阻塞（比如刚刚的例子中的情况（除非不需要持久化）
2. 纵向扩展会受到硬件和成本的限制

横向拓展：

1. 在面向百万、千万级别的用户规模时，横向扩展的 Redis 切片集群会是一个非常好的选择。







### 数据切片和实例的对应分布关系

实际上，**切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案**。在 Redis 3.0 之前，官方并没有针对切片集群提供具体的方案。从 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。Redis Cluster 方案中就规定了数据和实例的对应规则。

具体来说，Redis Cluster 方案采用哈希槽（Hash Slot，接下来我会直接称之为 Slot），来处理数据和实例之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。

具体的映射过程分为两大步：首先根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。关于 CRC16 算法，不是这节课的重点，你简单看下链接中的资料就可以了。

数据、哈希槽、实例这三者的映射分布情况。

![img](https://i.loli.net/2021/03/26/4HE71rpMbzxKAdl.jpg)

**在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。**





### 客户端如何定位数据（定位对应的哈希槽在哪个实例上）

一般来说，客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的。

那么，客户端为什么可以在访问任何一个实例时，都能获得所有的哈希槽信息呢？这是因为，**Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了**。

**客户端收到哈希槽信息后，会把哈希槽信息缓存在本地**。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。



但是，在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：

- 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽；
- 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。

此时，实例之间还可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客户端是无法主动感知这些变化的。这就会导致，它缓存的分配信息和最新的分配信息就不一致了，那该怎么办呢？Redis Cluster 方案提供了一种重定向机制，所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。

```
GET hello:key
(error) MOVED 13320 172.16.19.5:6379
```

![img](https://i.loli.net/2021/04/07/aZVtrW3pXboCuq6.jpg)



在实际应用时，如果 Slot 2 中的数据比较多，就可能会出现一种情况：客户端向实例 2 发送请求，但此时，Slot 2 中的数据只有一部分迁移到了实例 3，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到一条 ASK 报错信息，如下所示：

```
GET hello:key
(error) ASK 13320 172.16.19.5:6379
```

这个结果中的 ASK 命令就表示，客户端请求的键值对所在的哈希槽 13320，在 172.16.19.5 这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给 172.16.19.5 这个实例发送一个 ASKING 命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送 GET 命令，以读取数据。

![img](https://i.loli.net/2021/04/07/4moXVYPjIGTJvSO.jpg)

ASK 命令表示两层含义：第一，表明 Slot 数据还在迁移中；第二，ASK 命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例 3 发送 ASKING 命令，然后再发送操作命令。

和 MOVED 命令不同，**ASK 命令并不会更新客户端缓存的哈希槽分配信息。**所以，在上图中，如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。这也就是说，ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例。


